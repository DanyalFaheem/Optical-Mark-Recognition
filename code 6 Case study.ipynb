{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bd7fb1-821a-4613-9fd8-d64a50008efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f552d8-6c42-46b8-9be1-22ec7b9e14fa",
   "metadata": {},
   "source": [
    "### Working with Videos Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eef9328-a602-4afe-8460-16835ac79986",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bfa6a917bbe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# For camera use camera port ID like 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# For video use Video Path as string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "path = r'F:\\img\\videos\\news.mp4'\n",
    "\n",
    "# For camera use camera port ID like 0 \n",
    "# For video use Video Path as string\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "try:\n",
    "    if (cap.isOpened()== False): \n",
    "        raise Exception('Error opening video stream or file')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = int(fps)\n",
    "#     fps /= 1000\n",
    "#     print(fps)\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.GaussianBlur(gray, (5,5), 0) \n",
    "\n",
    "            # Sobel Edge Detection x direction\n",
    "            sobelx = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=3) \n",
    "            # Sobel Edge Detection on the Y axis\n",
    "            sobely = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=3) \n",
    "            \n",
    "            mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "#             theta = np.arctan2(sobely,sobelx)\n",
    "            cv2.normalize(mag, mag, alpha=0,beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    \n",
    "            edgesCanny = cv2.Canny(gray, threshold1=50, threshold2=150) \n",
    "    \n",
    "            edges = mag.astype(np.uint8)\n",
    "            edges = edgesCanny\n",
    "            cv2.imshow('Video',edges)\n",
    "            \n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(fps) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "except Exception as x:\n",
    "      print(x)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    print('Video Object Released.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cac6b1-5f46-45b6-b20a-eb3138cfbcf0",
   "metadata": {},
   "source": [
    "### Working with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4168ff-29ac-47c1-923a-356953c2ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Object Released.\n"
     ]
    }
   ],
   "source": [
    "# For camera use camera port ID like 0 \n",
    "# For video use Video Path as string\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    if (cap.isOpened()== False): \n",
    "        raise Exception('Error opening video stream or file')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = int(fps)\n",
    "#     fps /= 1000\n",
    "#     print(fps)\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.GaussianBlur(gray, (3,3), 0) \n",
    "\n",
    "            # Canny Edge Detection x direction\n",
    "            edgesCanny = cv2.Canny(gray, threshold1=20, threshold2=40) \n",
    "    \n",
    "            edges = mag.astype(np.uint8)\n",
    "            edges = edgesCanny\n",
    "            cv2.imshow('Video',edges)\n",
    "            \n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(fps) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "except Exception as x:\n",
    "      print(x)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    print('Video Object Released.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e65c8a6d-c195-415b-8666-0bafdacd5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Working with Ip Camera  Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754db96f-e12a-454f-83e3-de4a4328669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Object Released.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b6752cd2ec19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Read until video is completed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = r'http://172.16.48.196:8080/video'\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# For camera use camera port ID like 0 \n",
    "# For video use Video Path as string\n",
    "cap = cv2.VideoCapture(path)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH,340)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT,220)\n",
    "\n",
    "# print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "scale = 0.5\n",
    "try:\n",
    "    if (cap.isOpened()== False): \n",
    "        raise Exception('Error opening video stream or file')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = int(fps)\n",
    "#     fps /= 1000\n",
    "#     print(fps)\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        frame =  cv2.resize(frame,(int(frame.shape[1]*scale),int(frame.shape[0]*scale)),interpolation=cv2.INTER_CUBIC)\n",
    "        width, height,c = frame.shape\n",
    "        if ret == True:\n",
    "            gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.GaussianBlur(gray, (5,5), 0) \n",
    "            \n",
    "\n",
    "            edges = cv2.Canny(gray, threshold1=30, threshold2=100) \n",
    "#             edges = cv2.Laplacian(gray, cv2.CV_16S, ksize=5)\n",
    "            edges = edges.astype(np.uint8)\n",
    "            \n",
    "            edges = cv2.merge([edges,edges,edges])\n",
    "            temp = np.random.randint(low=1, high=255, size=edges.shape,dtype=np.uint8)\n",
    "            edges =  cv2.bitwise_and(temp,edges)\n",
    "            edges[0:edges.shape[0]-1,0:edges.shape[1]//2,:] = frame[0:edges.shape[0]-1,0:edges.shape[1]//2,:]\n",
    "#             edges[0:540,0:480,:] =255\n",
    "#             print(temp.shape, frame.shape)\n",
    "            edges = cv2.GaussianBlur(edges, (5,5), 0)\n",
    "            cv2.imshow('Video ' + str(edges.shape[2]),edges)\n",
    "            \n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(fps) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "except Exception as x:\n",
    "      print(x)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    print('Video Object Released.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6564b-49aa-4de3-93d5-702882a29f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'F:\\img\\coins.jpg'\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec12b71-69e4-4a9a-b92d-24add750adda",
   "metadata": {},
   "source": [
    "### Sobel Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730e37b-8f4a-4fab-afa2-8f94524bc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.GaussianBlur(img, (3,3), 0) \n",
    "\n",
    "# Sobel Edge Detection x direction\n",
    "sobelx = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=3) \n",
    "# Sobel Edge Detection on the Y axis\n",
    "sobely = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=3) \n",
    "# Both in  X and Y direction\n",
    "sobelxy = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=3) \n",
    "\n",
    "fig, axs = plt.subplots(1,4,figsize=(16,8))\n",
    "# fig.suptitle('Brightness changes')\n",
    "axs[0].imshow(img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].imshow(sobelx,cmap='gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Sobel in x-direction',fontsize='medium')\n",
    "\n",
    "axs[2].imshow(sobely,cmap='gray')\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('Sobel in y-direction',fontsize='medium')\n",
    "\n",
    "\n",
    "axs[3].imshow(cv2.convertScaleAbs(sobelxy),cmap='gray')\n",
    "axs[3].axis('off')\n",
    "axs[3].set_title('Sobel in xy-direction',fontsize='medium')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0dbafa-959d-46e1-8bc3-7b6a408f00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.convertScaleAbs(sobelxy),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Sobel in xy-direction',fontsize='medium')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c47e0-c838-47ec-8d4b-4deee3a97c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "absimg = cv2.convertScaleAbs(sobelxy)\n",
    "out, thresh1 = cv2.threshold(absimg, 120, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "plt.imshow(thresh1,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Sobel in xy-direction',fontsize='medium')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be5d94-233e-474a-a20b-2df65fac70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "theta = np.arctan2(sobely,sobelx)\n",
    "\n",
    "mag = mag.astype(np.uint8)\n",
    "absimg = cv2.convertScaleAbs(sobelxy)\n",
    "# type(mag[0,0])\n",
    "# mag.dtype\n",
    "theta.dtype\n",
    "out, thresh1 = cv2.threshold(mag, 120, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "plt.imshow(thresh1,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Sobel in xy-direction',fontsize='medium')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc186b8-59b7-4684-9ee6-9ade367470b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With larger Gaussian blur\n",
    "plt.figure(figsize=(16, 8))\n",
    "blur = cv2.GaussianBlur(img, (7,7), 0) \n",
    "\n",
    "# Sobel Edge Detection x direction\n",
    "sobelx = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=3) \n",
    "# Sobel Edge Detection on the Y axis\n",
    "sobely = cv2.Sobel(src=blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=3) \n",
    "mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "theta = np.arctan2(sobely,sobelx)\n",
    "\n",
    "mag = mag.astype(np.uint8)\n",
    "absimg = cv2.convertScaleAbs(sobelxy)\n",
    "# type(mag[0,0])\n",
    "# mag.dtype\n",
    "theta.dtype\n",
    "thresh1, out  = cv2.threshold(mag, 120, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "plt.imshow(out,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Sobel in xy-direction',fontsize='medium')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19551cd-f52d-42ca-bca5-af9ef72e42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detection\n",
    "# blur = cv2.GaussianBlur(img, (7,7), 0) \n",
    "edgesCanny = cv2.Canny(img, threshold1=100, threshold2=200) \n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(edgesCanny,cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Canny Edges',fontsize='medium')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f6ab4-c1fa-4ed4-a859-4d0d2f2896c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplacian\n",
    "path = r'F:\\img\\coins.jpg'\n",
    "size = 3\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "out = cv2.Laplacian(img, cv2.CV_16S, ksize=size)\n",
    "out = cv2.convertScaleAbs(out)\n",
    "# thresh1, out  = cv2.threshold(out, 120, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# thresh1, out  = cv2.threshold(out, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,16))\n",
    "axs[0].imshow(img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].imshow(out,cmap='gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Laplacian',fontsize='medium')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff81a4b-e2da-4942-8737-691595799029",
   "metadata": {},
   "source": [
    "### Image Histograms cv::calcHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7116b-00ac-46d4-a9b1-fe58d24c1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path =r'F:\\DIP_Images\\DIP3E_CH03\\Fig0310(b)(washed_out_pollen_image).tif'\n",
    "img = cv2.imread(path)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "hist = cv2.calcHist(img, [0], None, [256], (0, 256), accumulate=False)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,16))\n",
    "axs[0].imshow(img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].plot(hist, color='r')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Histogram',fontsize='medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4801c5d6-2a28-4bfe-b570-c9fd0ef1b793",
   "metadata": {},
   "source": [
    "### Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f90855-4621-4e11-8989-a8d4bdccbc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laplacian\n",
    "# path = r'F:\\img\\coins.jpg'\n",
    "path =r'F:\\DIP_Images\\DIP3E_CH03\\Fig0310(b)(washed_out_pollen_image).tif'\n",
    "img = cv2.imread(path)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "out = cv2.equalizeHist(gray)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,16))\n",
    "axs[0].imshow(img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].imshow(out,cmap='gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Laplacian',fontsize='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1652b-aebb-4a36-973f-1258040fdd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "hist = cv2.calcHist(out, [0], None, [256], (0, 256), accumulate=False)\n",
    "axs[0].imshow(out,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].plot(hist, color='r')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Equalized Histogram',fontsize='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5fccc-0aa1-4ea7-baa8-cfc583c9b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize an array by using the function cv::normalize\n",
    "fig, axs = plt.subplots(1,2,figsize=(8,8))\n",
    "hist = cv2.calcHist(out, [0], None, [256], (0, 256), accumulate=False)\n",
    "cv2.normalize(hist, hist, alpha=0,beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "axs[0].imshow(out,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].plot(hist, color='r')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Equalized Histogram',fontsize='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fc69e-9272-4b05-923b-c3d2e9b92a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv::split to divide an image into its correspondent channels.\n",
    "\n",
    "path = r'F:\\img\\lena.jpg'\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "fig, axs = plt.subplots(1,4,figsize=(16,8))\n",
    "channels = cv2.split(img)\n",
    "axs[0].imshow(img,cmap='gray')\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image',fontsize='medium')\n",
    "\n",
    "axs[1].imshow(channels[0],cmap='gray')\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Blue',fontsize='medium')\n",
    "\n",
    "axs[2].imshow(channels[0],cmap='gray')\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('Green',fontsize='medium')\n",
    "\n",
    "axs[3].imshow(channels[0],cmap='gray')\n",
    "axs[3].axis('off')\n",
    "axs[3].set_title('Red',fontsize='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736cbfbb-9cbf-4875-b882-f102eddac9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge\n",
    "out = cv2.merge([channels[0], channels[1],channels[2]])\n",
    "plt.imshow(out)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec2a0c-12ab-4f62-9557-dc99ee3aecf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
